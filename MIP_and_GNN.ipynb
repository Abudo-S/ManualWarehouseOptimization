{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7SXFPrdx-tj"
      },
      "source": [
        "## Multi-criteria Objective Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJjogrJ9ut_C"
      },
      "source": [
        "### MIP Problem Definition\n",
        "* Sets: J (Orders/Missions), $I_{max}$ (Max number of operators), U (Order types).\n",
        "Note that J can be expanded in $J' = J \\cup \\{\\text{0}\\}$ in order to have the initial base virual node.\n",
        "* Variables: $x_{ij}$ (Assignment), $S_{j}$ (Start Time), ${Cj}$ (Completion Time), $y_{i}$ (Operator Activation), $S_{i, first}$(Operator Start Time), $C_{i, last}$(Operator Completion Time), Z (Makespan)\t  \n",
        "Sequencing variable: $z_{ikj}$ (operator i goes from order k to order j)\n",
        "* Parameters:\n",
        "  - $P_{ij}$(Processing time) => time of loading and unloading of pallet j.\n",
        "  - $T{jk}$ (Travel time from j to k) => calculated basing on any possible.combination between two orders i and k.\n",
        "  - $Q{it}$ (Skill score) => the score that a fork_lift is adequate to pallet dimensions and its enabled to elaborate it.\n",
        "  - $O{jt}$ (Order type) => contains the pallet/mission type for each order.\n",
        "  - $H_{fixed}$ (Work hours per operator/machine)\n",
        "  - M (Big number)\n",
        "\n",
        "*Note that all time units should be standarized {shift time, operator speed that affect the processing time, ...}, any distances are misured in \"meter\", any time is mesured in \"minute\" and speeds are misured in meter/minute.  \n",
        "*Note that aiming to have a less loss in fork space it'll open another optimization question by adding another criteria in our objective function. So as a semplification, we would ignore this condition.\n",
        "\n",
        "#### Constaints and Objective function\n",
        "\n",
        "1. Each order j is assigned to a single operator i\n",
        "$$\\sum_{i \\in I{max}} x_{i j} = 1 \\quad \\forall j \\in J$$\n",
        "\n",
        "2. The type of order j should be handled by an operator i that has skill score >= 1 for such order\n",
        " $$\\sum_{u \\in U} O_{j u} \\cdot Q_{i, u} \\ge x_{i j} \\quad \\forall i \\in I_{max}, j \\in J$$\n",
        "\n",
        "3. The linking between order k and order j over the same operator i\n",
        " $$\\sum_{k \\in J \\cup \\{\\text{Base}\\}} z_{i k j} = x_{i j} \\quad \\forall i \\in I_{max}, j \\in J$$\n",
        "(The operator i must travel to j if and only if i is assigned to j.)\n",
        "\n",
        "4. the number of flow-ins (j->k) should be equal to the number flow-outs (l->j) of the same operator i for any order j\n",
        "$$\\sum_{k \\in J \\cup \\{\\text{Base}\\}} z_{i j k} = \\sum_{l \\in J \\cup \\{\\text{Base}\\}} z_{i l j} \\quad \\forall i \\in I_{max}, j \\in J \\text{ and } k \\ne l$$\n",
        "(Including both directions towards the base)\n",
        "\n",
        "5. Time sequencing (the start time of order k is after the completion time of the previous linked order j + the travel time to reach order k)\n",
        "$$S_k \\ge C_j + T_{j k} - M \\cdot (1 - z_{i j k}) \\quad \\forall i \\in I_{max}, j, k \\in J, j \\ne k$$\n",
        "(M is a big number that activate the constraint in case of linking order k and order j; otherwise, the constraint give a very large negative number)\n",
        "\n",
        "6. The completion time of order j is the time to start it + the processing time w.r.t. the assigned operator i\n",
        "$$C_j = S_j + \\sum_{i \\in I} x_{i, j} \\cdot P_{i j} \\quad \\forall j \\in J, i \\in I_{max}$$\n",
        "7. Common MTZ (Miller-Tucker-Zemlin) constraints to prevent isolated loops/subtours\n",
        " $$u_j - u_k + |J| \\cdot z_{i j k} \\le |J| - 1 \\quad \\forall i \\in I_{max}; j, k \\in J, j \\ne k$$\n",
        "(Where $u_{j}$ and $u_{k}$ are helper variables representing the sequence position of j and k on the route,   \n",
        "and $2 \\le u_{j} \\le |J|+1$.)\n",
        "\n",
        "8. An order j can only be assigned to operator i if and only if the operator i is activated $(y_{i}=1)$.\n",
        "$$x_{i j} \\le y_{i} \\forall i \\in I_{max},j \\in J$$\n",
        "\n",
        "9. The time elapsed between an operator's first assigned task and his last assigned task must not exceed the fixed shift length $H_{fixed}$.\n",
        "$$C_{i,last} - S_{i,first} \\le H_{fixed}⋅y_{i} \\forall i \\in I_{max}$$\n",
        "\n",
        "      - $C_{i,last}$: The completion time of last task per operator i.\n",
        "\n",
        "      - $S_{i,first}$: The start time of first task per operator i.\n",
        "\n",
        "      - Note that: $P_{i,0}=0$, $S_{0}=0, C_{0}=0$\n",
        "\n",
        "      - (This requires additional constraints to define $C_{i,last}$ and $S_{i,first}$ based on the $z_{ijk}$ sequencing variables and a virtual Base node):\n",
        "        * $S_{i,first}=S_{k}$ $\\text{if } z_{i,0,k}=1$\n",
        "        * $C_{i,last}=C_{j}+T_{j,0}$ $\\text{if } z_{i,j,0}=1$\n",
        "\n",
        "10. The total number of trips that end at the Base (k=0) must equal the number of operators who are activated ($y_{i}=1$).\n",
        "$$\\sum_{j \\in J} z_{ij0} =y_{i} \\forall i \\in I_{max}$$\n",
        "\n",
        "11. Objective function (multi-objective): minimize the overall time to complete all orders (Makespan) AND minimize the fixed cost of labor (the number of operators used).\n",
        "$$\\text{Minimize } Z=(\\alpha⋅Z)+(\\beta⋅ \\sum_{i \\in I_{max}}y_{i​})$$\n",
        "\n",
        "    - Z: The Makespan (maximum completion time, costed by α).\n",
        "\n",
        "    - $\\sum_{i\\in I_{max}}y_{i​}$: The total number of operators used (costed by β).\n",
        "\n",
        "    - $\\alpha, \\beta$: Weighting factors you choose to define the trade-off. (α high = minimize time; β high = minimize staff).\n",
        "\n",
        "    - $I_{max}$: The set of all available operators we could potentially use (unactivated operators).\n",
        "\n",
        "*Base order/mission is at position [0, 0], from which all operator should start the day."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HujqYsabO-kw"
      },
      "source": [
        "### GNN Problem Definition\n",
        "\n",
        "The graph $\\mathcal{G}=(\\mathcal{V}, \\mathcal{E})$ must capture all orders, all potential resources, and all spatial relationships necessary for the GNN to make an informed, multi-objective decision.\n",
        "\n",
        "* Nodes ($\\mathcal{V}$)\n",
        "  - Order Nodes $J$ (up to 10,000): Initial Features ($h_v$) => Location coordinates $(x_j, y_j)$, Required Skill ID, Processing Time ($P_{ij}$).\n",
        "  - Operator Nodes $I_{max}$ (Pool): Initial Features ($h_v$) => Current Location, Operator Skill Set, Fixed Shift Capacity ($H_{fixed}$), Status (Idle/Busy).\n",
        "\n",
        "* Edges ($\\mathcal{E}$)\n",
        "  - Order-Order ($\\boldsymbol{e_{jk}}$) featured with \"Travel Time $T_{jk}$\": Represents the static distance map of the warehouse (ex. calculated with A*).\n",
        "  - Operator-Order ($\\boldsymbol{e_{ij}}$) featured with current \"Travel Time $T_{i, j}$\": Represents the dynamic accessibility of $\\text{Order}_j$ by $\\text{Operator}_i$ from their current position.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgdITjc0kNga"
      },
      "source": [
        "### GNN Architecture\n",
        "* Message Passing Layers: These layers iteratively compute a contextual node embedding for every order and operator by aggregating information from their neighbors. This allows the GNN to understand complex trade-offs, such as: \"This order is close to Operator A, but Operator B is already assigned nearby tasks, making Operator B's route more efficient.\"B.\n",
        "\n",
        "  * Dual Processing (Hidden Layers): The GNN's deep Message Passing layers are trained to understand the complex relationship between scheduling efficiency and labor cost.\n",
        "    - Layer 1: Assignment Policy ($P_{assign}(i, j)$): This requires a set of weights ($W_{assign}$) and biases ($b_{assign}$) to map the GNN's final node embeddings to the assignment scores. This is a large layer, as it covers all $I_{max} \\times J$ potential assignments.\n",
        "    - Layer 2: Activation Policy ($P_{activate}(i)$): This requires a separate set of weights ($W_{activate}$) and biases ($b_{activate}$) to map the operator node embeddings to the activation scores ($y_i$). This layer must learn a distinct function specific to resource capacity.\n",
        "\n",
        "    During this phase, the network learns features relevant to both:\n",
        "    - Resource Features: Embeddings learn if an operator is \"cost-effective\" to activate (reflecting the $\\beta$ penalty).\n",
        "    - Scheduling Features: Embeddings learn the optimal sequence and travel time (reflecting the $\\alpha$ penalty).\n",
        "\n",
        "* Single Output Layer (Assignment Policy $\\pi$):\n",
        " The final layer outputs only the Assignment Score ($P_{assign}(i, j)$) for every possible $\\text{Operator}_i$ to $\\text{Order}_j$ pair. This score reflects the GNN's learned opinion on whether that assignment is globally optimal.\n",
        " Operators with no associated assignments (missions) are considered \"unactivated\".\n",
        "\n",
        " * Final Weighted Loss ($\\mathcal{L}_{\\text{Total}}$):  \n",
        " The final loss value, which is minimized during training, is the weighted combination of these two aggregated errors:$$\\mathcal{L}_{\\text{Total}} = \\left( \\alpha \\cdot \\mathcal{L}_{\\text{Scheduling}} \\right) + \\left( \\beta \\cdot \\mathcal{L}_{\\text{Activation}} \\right)$$\n",
        "\n",
        "    - Total Activation LossThe total activation error is the sum of local errors across all potential operator nodes:$$L_{{Activation}} = \\sum_{i \\in I_{\\text{max}}} \\text{BCE}(\\hat{y}_i \\text{ vs } y_i^*)$$\n",
        "    - Total Scheduling LossThe total scheduling error is the sum of local errors across all potential sequencing flows (edges):$$L_{\\text{Scheduling}} = \\sum_{i \\in I_{\\text{max}}} \\sum_{j, k \\in J,  j \\ne k} \\text{BCE}(z_{ijk} \\text{ vs } z_{ijk}^*)$$\n",
        "\n",
        "    This process ensures that every decision point in the system—whether it's the strategic choice to activate an operator ($L_{\\text{Activation}}$) or the tactical choice of sequence ($L_{\\text{Scheduling}}$), contributes to the single error signal used to update the GNN's parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlYgCPxb0MPl"
      },
      "source": [
        "### New Alternatives:\n",
        "Monolithic MIP solver has a limit for 50~100 orders at most, making it even undesirable in generating training data, because of the few number of training example. So as alternative, we could consider:\n",
        "- Decomposition technique that guarantee the optimality (column generation):  \n",
        "    The problem structure is a Set Covering Problem (or Set Partitioning) at the top level, which is the master problem framework for column generation.  \n",
        "    The primary difficulty in Vehicle Routing Problems (VRP) is the massive number of possible routes (complicating variables). A forklift route that services 10 orders can be arranged in 10! ways. If we have 100 orders, we'll have an astronomical number of possible routes, which no monolithic solver can handle.\n",
        "\n",
        "    * Column Generation Solution: The algorithm generates only the few, most valuable routes (columns) needed to cover all orders optimally, considering this type of decomposition:  \n",
        "\n",
        "        - Master Problem: Decides which routes (columns) to select to cover all orders while minimizing the number of operators (fleet size).\n",
        "\n",
        "        - Subproblem (Pricing Problem): Finds a single, most profitable route (new column) to add to the Master Problem's choice set. This subproblem is a Shortest Path Problem with Resource Constraints (SPPRC).\n",
        "\n",
        "    * Handling the Objectives:\n",
        "\n",
        "        - Minimize Operators: This is the natural objective of the Master Problem (a Set Covering formulation).\n",
        "\n",
        "        - Minimize Makespan: This constraint can be handled by adding a time limit (resource constraint) in the Subproblem (the SPPRC), ensuring only routes below a maximum duration are generated.\n",
        "\n",
        "- MIP Column Generation + GNN:\n",
        "    We might use a decomposed MIP (CG) model to generate a larger number of training examples in order to train the GNN model, then the GNN is used to solve large-scale problems.\n",
        "    Note that we can use the decomposed MIP (CG) model directly to solve problems with n.missions < 500"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTHBXDST1aRs"
      },
      "source": [
        "### How MIP decomposition guarantees the optimality?\n",
        "It's reasonable to say that after decomposition in master (which minimizes the number of operators to activate) and subproblem (which minimizes the makespan of a sequence of orders), the subproblem just finds \"the shortest route\" and ignores the fleet size, so it may not considered as an optimal approach!\n",
        "\n",
        "Effectively, the decomposition through column generation of a monolothic MIP can reach the optimality. It shall follow an iterative process in which the subproblem's \"Reduced Cost\" need to converge towards a non-negative value in the entire solution space (per any column); otherwise, it'll produce only a bound, not the optimum.\n",
        "\n",
        "The Master Problem sends Dual Values (Shadow Prices) to the Subproblem, so it work as the following:\n",
        "\n",
        "  * If Order A is currently uncovered and \"expensive\" to cover in the Master, the Master assigns it a high \"reward\" (dual value).\n",
        "\n",
        "  * The Subproblem changes its objective. It no longer looks for the shortest route; it looks for the most profitable route (Reduced Cost).\n",
        "\n",
        "  * Formula: The Subproblem optimizes $Cost_{route} - \\sum Reward_{orders}$.\n",
        "\n",
        "  * Result: The Subproblem effectively says, \"I found a weird, long route, but it covers these 3 difficult orders you are struggling with.\" This perfectly aligns the local search with the global goal.\n",
        "\n",
        "### Even for decomposed MIP in the optimal CG, remains anyway the challenge of common large-scale VRP (10,000 Orders)\n",
        "The VRP is an NP-hard problem, and the number of potential routes grows exponentially with the number of customers. Even for instances with only 15 customers, the number of possible routes is staggering. A problem with 10,000 orders presents two major computational barriers:\n",
        "\n",
        "  * Exact Solution Intractability: Exact methods like Branch-and-Price (B&P), which rely on CG, are typically limited to instances with fewer than 1,000 nodes (customers), often solving instances with 50 to a few hundred nodes to proven optimality.\n",
        "\n",
        "  * Resource-Constrained Shortest Path Problem (RCESPP): The Subproblem (the pricing problem) in CG is the RCESPP, which is itself NP-hard. The time required to solve the RCESPP increases rapidly as constraints (like time windows, makespan, and capacity) are added. Attempting to solve 10,000 unique customer RCESPPs repeatedly across hundreds of iterations for an exact solution is computationally prohibitive.\n",
        "\n",
        "*the global and local optimalities can be reached in case of moderate set of orders (limited < 1000), and it depends on its scalability over a set of nodes.\n",
        "\n",
        "#### CG Scalability: The Decomposition Principle\n",
        "\n",
        "The scalability of CG comes from breaking a massive, \"monolithic\" problem into two interacting parts:\n",
        "\n",
        "  * The Restricted Master Problem (RMP): A version of the original problem containing only a small subset of possible variables (columns).\n",
        "\n",
        "  * The Pricing Subproblem: A separate, smaller optimization problem that \"searches\" for the next best variable to add to the Master Problem.\n",
        "\n",
        "Key Scalability Drivers:\n",
        "\n",
        "  - Memory Efficiency: You don't need to load all variables into memory. For example, in a Cutting Stock Problem, there are billions of ways to cut a roll of paper. CG only generates the dozen or so \"patterns\" that actually improve the current solution.\n",
        "\n",
        "  - Parallelization: The Pricing Subproblem can often be decomposed further. If you have 100 different vehicles to schedule, you can solve 100 independent pricing problems in parallel on different CPU cores.\n",
        "\n",
        "  - Tight Lower Bounds: When used within a Branch-and-Price framework, the Dantzig-Wolfe decomposition typically provides much \"tighter\" (more accurate) LP relaxations than the original compact formulation. This prunes the search tree significantly, preventing the \"exponential explosion\" of nodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFAPUoPEOxo-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
